{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12003148,"sourceType":"datasetVersion","datasetId":7550757},{"sourceId":12003359,"sourceType":"datasetVersion","datasetId":7550932},{"sourceId":12008765,"sourceType":"datasetVersion","datasetId":7554871},{"sourceId":12012380,"sourceType":"datasetVersion","datasetId":7557135},{"sourceId":12017358,"sourceType":"datasetVersion","datasetId":7560619},{"sourceId":12017393,"sourceType":"datasetVersion","datasetId":7560637},{"sourceId":12021536,"sourceType":"datasetVersion","datasetId":7563288}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile pix2pix_model.py\nimport os\nimport json\n\nimport numpy as np\nimport tensorflow as tf\nfrom datetime import datetime\n\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nfrom matplotlib import pyplot as plt\n\ndef define_discriminator(image_shape):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    \n    # ảnh source\n    in_src_image = Input(shape=image_shape)  \n    # ảnh target\n    in_target_image = Input(shape=image_shape) \n\n    # kết nối images, [256,256,6]\n    merged = Concatenate()([in_src_image, in_target_image])\n\n    # C64: 4x4 kernel Stride 2x2\n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C128: 4x4 kernel Stride 2x2\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C256: 4x4 kernel Stride 2x2\n    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C512: 4x4 kernel Stride 2x2\n    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # 4x4 kernel but Stride 1x1\n    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # patch output\n    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n    patch_out = Activation('sigmoid')(d)\n    # define model\n    model = Model([in_src_image, in_target_image], patch_out)\n    # compile model\n    opt = Adam(learning_rate=0.00005, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n    return model\n\ndef define_encoder_block(layer_in, n_filters, batchnorm=True):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # add downsampling layer\n    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    # conditionally add batch normalization\n    if batchnorm:\n        g = BatchNormalization()(g, training=True)\n    # leaky relu activation\n    g = LeakyReLU(alpha=0.2)(g)\n    return g\n\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # add upsampling layer\n    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    # add batch normalization\n    g = BatchNormalization()(g, training=True)\n    # conditionally add dropout\n    if dropout:\n        g = Dropout(0.5)(g, training=True)\n    # merge with skip connection\n    g = Concatenate()([g, skip_in])\n    # relu activation\n    g = Activation('relu')(g)\n    return g\n\ndef define_generator(image_shape=(256,256,3)):\n    # khởi tạo trọng số\n    init = RandomNormal(stddev=0.02)\n    # ảnh đầu vào\n    in_image = Input(shape=image_shape)\n    # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n    e2 = define_encoder_block(e1, 128)\n    e3 = define_encoder_block(e2, 256)\n    e4 = define_encoder_block(e3, 512)\n    e5 = define_encoder_block(e4, 512)\n    e6 = define_encoder_block(e5, 512)\n    e7 = define_encoder_block(e6, 512)\n    # bottleneck, no batch norm and relu\n    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n    b = Activation('relu')(b)\n    # decoder model: CD512-CD512-CD512-C512-C256-C128-C64\n    d1 = decoder_block(b, e7, 512)\n    d2 = decoder_block(d1, e6, 512)\n    d3 = decoder_block(d2, e5, 512)\n    d4 = decoder_block(d3, e4, 512, dropout=False)\n    d5 = decoder_block(d4, e3, 256, dropout=False)\n    d6 = decoder_block(d5, e2, 128, dropout=False)\n    d7 = decoder_block(d6, e1, 64, dropout=False)\n    # output\n    g = Conv2DTranspose(image_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n    out_image = Activation('tanh')(g)\n    # define model\n    model = Model(in_image, out_image)\n    return model\n\ndef define_gan(g_model, d_model, image_shape):\n    # make weights in the discriminator not trainable\n    for layer in d_model.layers:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = False\n\n    # define the source image\n    in_src = Input(shape=image_shape)\n    # supply the image as input to the generator\n    gen_out = g_model(in_src)\n    # supply the input image and generated image as inputs to the discriminator\n    dis_out = d_model([in_src, gen_out])\n    # src image as input, generated image and disc. output as outputs\n    model = Model(in_src, [dis_out, gen_out])\n    # compile model\n    opt = Adam(learning_rate=0.00005, beta_1=0.5)\n    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n    return model\n\ndef generate_real_samples(src_batch, tar_batch, n_patch):\n    batch_size = len(src_batch)\n    # Create target \"real\" class labels (1s)\n    y = ones((batch_size, n_patch, n_patch, 1))\n    return [src_batch, tar_batch], y\n\ndef generate_fake_samples(g_model, src_batch, n_patch):\n    # generate fake instance\n    X = g_model.predict(src_batch, verbose=0)\n    # create 'fake' class labels (0)\n    y = zeros((len(X), n_patch, n_patch, 1))\n    return X, y\n\ndef summarize_performance(step, g_model, data_generator, n_samples=3):\n    \"\"\"\n    Tóm tắt hiệu suất của mô hình bằng cách tạo và hiển thị ảnh\n    \"\"\"\n    # Lấy một batch ngẫu nhiên từ data generator\n    batch_idx = np.random.randint(0, len(data_generator))\n    src_batch, tar_batch = data_generator[batch_idx]\n    \n    # Chọn n_samples ảnh đầu tiên từ batch\n    n_samples = min(n_samples, src_batch.shape[0])\n    X_realA = src_batch[:n_samples]\n    X_realB = tar_batch[:n_samples]\n    \n    # Tạo ảnh fake từ generator\n    X_fakeB = g_model.predict(X_realA, verbose=0)\n    \n    # Chuẩn hóa pixel values từ [-1,1] về [0,1] để hiển thị\n    X_realA = (X_realA + 1) / 2.0\n    X_realB = (X_realB + 1) / 2.0\n    X_fakeB = (X_fakeB + 1) / 2.0\n    \n    # Tạo figure với kích thước phù hợp\n    plt.figure(figsize=(n_samples * 3, 9))\n    \n    # Hiển thị ảnh source (hàng 1)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + i)\n        plt.axis('off')\n        plt.title('Source', fontsize=10)\n        if X_realA[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_realA[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_realA[i])\n    \n    # Hiển thị ảnh generated (hàng 2)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples + i)\n        plt.axis('off')\n        plt.title('Generated', fontsize=10)\n        if X_fakeB[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_fakeB[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_fakeB[i])\n    \n    # Hiển thị ảnh target thực (hàng 3)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n        plt.axis('off')\n        plt.title('Target', fontsize=10)\n        if X_realB[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_realB[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_realB[i])\n    \n    # Điều chỉnh layout và lưu ảnh\n    plt.tight_layout()\n    filename1 = 'plot_epoch_%03d.png' % ((step // len(data_generator)) + 1)\n    plt.savefig(filename1, dpi=150, bbox_inches='tight')\n    plt.close()\n    \n    # Lưu mô hình generator\n    filename2 = 'g_model_epoch_%03d.h5' % ((step // len(data_generator)) + 1)\n    g_model.save(filename2)\n    \n    print(f'[INFO] Saved: {filename1} and {filename2}')\n\ndef train(d_model, g_model, gan_model, data_generator, n_epochs=100, checkpoint_dir='checkpoints'):\n    # tạo thư mục checkpoint nếu chưa có\n    if not os.path.exists(checkpoint_dir):\n        os.makedirs(checkpoint_dir)\n        \n    # Create log directory for TensorBoard\n    log_dir = 'logs/20250529-102933'\n    summary_writer = tf.summary.create_file_writer(log_dir)\n    \n    # file lưu trạng thái epoch\n    checkpoint_file = os.path.join(checkpoint_dir, 'checkpoint.json')\n    start_epoch = 0\n    \n    # nếu đã có checkpoint trước đó, load lại\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            checkpoint = json.load(f)\n            start_epoch = checkpoint.get('epoch', 0)\n            print(f\"[INFO] Resuming from epoch {start_epoch + 1}\")\n            # load lại trọng số mô hình\n            if os.path.exists(os.path.join(checkpoint_dir, 'd_model.weights.h5')):\n                d_model.load_weights(os.path.join(checkpoint_dir, 'd_model.weights.h5'))\n                g_model.load_weights(os.path.join(checkpoint_dir, 'g_model.weights.h5'))\n                gan_model.load_weights(os.path.join(checkpoint_dir, 'gan_model.weights.h5'))\n            \n    # lấy chiều cao trong discriminator (None, 16, 16, 1)\n    n_patch = d_model.output_shape[1]\n    # tính toán mỗi batch trong epoch\n    bat_per_epo = len(data_generator)\n    \n    print(f\"[INFO] Starting training from epoch {start_epoch + 1}\")\n    print(f\"[INFO] Patch shape: {n_patch}\")\n    print(f\"[INFO] Batches per epoch: {bat_per_epo}\")\n\n    # enumerate epochs\n    for epoch in range(start_epoch, n_epochs):\n        # Shuffle data at start of epoch\n        data_generator.on_epoch_end()\n        \n        for batch in range(bat_per_epo):\n            # current step\n            step = epoch * bat_per_epo + batch + 1\n            # Get batch data từ generator\n            src_batch, tar_batch = data_generator[batch]\n\n            # Generate real samples\n            [X_realA, X_realB], y_real = generate_real_samples(src_batch, tar_batch, n_patch)\n            \n            # Generate fake samples\n            X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n            \n            # Update discriminator for real samples\n            d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n            \n            # Update discriminator for fake samples\n            d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n            \n            # Update generator\n            g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n            \n            print('STEP : %d, Epoch : %d, Batch : %d/%d,  Discriminator_real[%.3f] Discriminator_fake[%.3f] Generator[%.3f]' % (step, epoch+1, batch+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n            \n            # Ghi loss vào TensorBoard sau mỗi step\n            with summary_writer.as_default():\n                tf.summary.scalar('Loss/Discriminator_real', d_loss1, step=step)\n                tf.summary.scalar('Loss/Discriminator_fake', d_loss2, step=step)\n                tf.summary.scalar('Loss/Generator', g_loss, step=step)\n                \n        # Lưu checkpoint sau mỗi epoch\n        d_model.save_weights(os.path.join(checkpoint_dir, 'd_model.weights.h5'))\n        g_model.save_weights(os.path.join(checkpoint_dir, 'g_model.weights.h5'))\n        gan_model.save_weights(os.path.join(checkpoint_dir, 'gan_model.weights.h5'))\n        with open(checkpoint_file, 'w') as f:\n            json.dump({'epoch': epoch + 1}, f)\n            \n        # Tóm tắt hiệu suất mỗi 10 epoch\n        if (epoch + 1) % 10 == 0:\n            summarize_performance(step, g_model, data_generator, n_samples=3)\n            \n    print(f\"[INFO] Training completed after {n_epochs} epochs\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from os import listdir\nfrom numpy import asarray, load\nfrom numpy import vstack\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nfrom matplotlib import pyplot\nimport numpy as np\nimport os\nfrom pix2pix_model import define_discriminator, define_generator, define_gan, train","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\nclass ImageDataGenerator(Sequence):\n    def __init__(self, sat_path, mask_path, batch_size=16, size=(256, 256), max_images=10000, shuffle=True):\n        self.sat_path = sat_path\n        self.mask_path = mask_path\n        self.batch_size = batch_size\n        self.size = size\n        self.max_images = max_images\n        self.shuffle = shuffle\n        \n        # Lấy danh sách file từ cả 2 folder\n        sat_files = set(os.listdir(sat_path))\n        mask_files = set(os.listdir(mask_path))\n        \n        # Chỉ lấy các file có trong cả 2 folder (intersection)\n        common_files = sat_files.intersection(mask_files)\n        self.image_files = [f for f in list(common_files)[:max_images] \n                           if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.tif', '.tiff'))]\n        \n        # Tạo indices cho shuffle\n        self.indices = np.arange(len(self.image_files))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n            \n        print(f\"Data Generator initialized:\")\n        print(f\"- Satellite images folder: {sat_path}\")\n        print(f\"- Mask images folder: {mask_path}\")\n        print(f\"- Common images found: {len(self.image_files)}\")\n        print(f\"- Total batches: {len(self)}\")\n        \n    def __len__(self):\n        return len(self.image_files) // self.batch_size\n    \n    def __getitem__(self, batch_idx):\n        # Lấy indices cho batch này\n        start_idx = batch_idx * self.batch_size\n        end_idx = (batch_idx + 1) * self.batch_size\n        batch_indices = self.indices[start_idx:end_idx]\n        \n        sat_batch, mask_batch = [], []\n        \n        for idx in batch_indices:\n            filename = self.image_files[idx]\n            sat_path = os.path.join(self.sat_path, filename)\n            mask_path = os.path.join(self.mask_path, filename)\n            \n            try:\n                # Load satellite image\n                sat_img = load_img(sat_path, target_size=self.size)\n                sat_img = img_to_array(sat_img)\n                \n                # Load mask image\n                mask_img = load_img(mask_path, target_size=self.size)\n                mask_img = img_to_array(mask_img)\n                \n                sat_batch.append(sat_img)\n                mask_batch.append(mask_img)\n                \n            except Exception as e:\n                print(f\"Error loading {filename}: {e}\")\n                continue\n        \n        # Preprocess data (scale to [-1,1])\n        sat_batch = np.array(sat_batch)\n        mask_batch = np.array(mask_batch)\n        \n        sat_batch = (sat_batch - 127.5) / 127.5\n        mask_batch = (mask_batch - 127.5) / 127.5\n        \n        return sat_batch, mask_batch\n    \n    def on_epoch_end(self):\n        \"\"\"Shuffle data sau mỗi epoch\"\"\"\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n    \n    def show_samples(self, num_samples=5):\n        \"\"\"Hiển thị một số mẫu ảnh satellite và mask tương ứng\"\"\"\n        # Lấy một batch để hiển thị\n        sat_batch, mask_batch = self.__getitem__(0)\n        \n        # Giới hạn số lượng samples hiển thị\n        num_samples = min(num_samples, len(sat_batch))\n        \n        fig, axes = plt.subplots(2, num_samples, figsize=(4*num_samples, 8))\n        if num_samples == 1:\n            axes = axes.reshape(2, 1)\n        \n        for i in range(num_samples):\n            # Chuyển về scale [0,1] để hiển thị\n            sat_display = (sat_batch[i] + 1) / 2\n            mask_display = (mask_batch[i] + 1) / 2\n            \n            # Hiển thị ảnh satellite\n            axes[0, i].imshow(sat_display)\n            axes[0, i].set_title(f'Satellite {i+1}')\n            axes[0, i].axis('off')\n            \n            # Hiển thị ảnh mask\n            axes[1, i].imshow(mask_display)\n            axes[1, i].set_title(f'Mask {i+1}')\n            axes[1, i].axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        return sat_batch, mask_batch\n\n\n# Khởi tạo data generator với đường dẫn folder riêng biệt\ndata_generator = ImageDataGenerator(\n    sat_path='/kaggle/input/datapainting2/inpainting/mask',      \n    mask_path='/kaggle/input/datapainting2/inpainting/real',     \n    batch_size=16,\n    size=(256, 256),         # Kích thước ảnh\n    max_images=10000,\n    shuffle=True\n)\n\nprint(f\"Total batches: {len(data_generator)}\")\nprint(f\"Total images: {len(data_generator.image_files)}\")\n\n# Hiển thị một số mẫu ảnh để kiểm tra\nprint(\"\\nHiển thị 5 mẫu ảnh đầu tiên:\")\nsample_sat, sample_mask = data_generator.show_samples(num_samples=5)\n\n# Kiểm tra shape của data\nprint(f\"\\nShape của satellite batch: {sample_sat.shape}\")\nprint(f\"Shape của mask batch: {sample_mask.shape}\")\nprint(f\"Range của satellite data: [{sample_sat.min():.3f}, {sample_sat.max():.3f}]\")\nprint(f\"Range của mask data: [{sample_mask.min():.3f}, {sample_mask.max():.3f}]\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test load một batch\ntry:\n    sample_src, sample_tar = data_generator[0]\n    print(f\"Source batch shape: {sample_src.shape}\")\n    print(f\"Target batch shape: {sample_tar.shape}\")\n    print(f\"Data range: [{sample_tar.min():.3f}, {sample_tar.max():.3f}]\")\n    \n    image_shape = sample_tar.shape[1:]  # (256, 256, 3)\n    print(f\"Image shape for model: {image_shape}\")\n    \nexcept Exception as e:\n    print(f\"Error testing generator: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Copy từ /kaggle/input/ về /kaggle/working nếu cần ghi thêm\nimport shutil\nimport zipfile\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src = '/kaggle/input/tamthoi5/checkpoints/checkpoints'\ndst = '/kaggle/working/checkpoints'\n\nif not os.path.exists(dst):\n    shutil.copytree(src, dst)\n    print(\"✅ Đã copy thư mục checkpoints từ input vào working\")\nelse:\n    print(\"📁 Thư mục checkpoints đã tồn tại trong working\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src = '/kaggle/input/tamthoi5/logs/logs'\ndst = '/kaggle/working/logs'\n\nif not os.path.exists(dst):\n    shutil.copytree(src, dst)\n    print(\"✅ Đã copy thư mục logs từ input vào working\")\nelse:\n    print(\"📁 Thư mục logs đã tồn tại trong working\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\n# Lấy image shape từ một batch đầu tiên\nsample_src, sample_tar = data_generator[0]\nimage_shape = sample_src.shape[1:]  # (256, 256, 3)\n\n# Define models\nd_model = define_discriminator(image_shape)\ng_model = define_generator(image_shape)\ngan_model = define_gan(g_model, d_model, image_shape)\n\n# Training\nstart_time = datetime.now()\nprint(f\"Training started at: {start_time}\")\n\ntrain(d_model, g_model, gan_model, data_generator, \n      n_epochs=600, checkpoint_dir='/kaggle/working/checkpoints')\n\nend_time = datetime.now()\nexecution_time = end_time - start_time\nprint(f\"Training completed at: {end_time}\")\nprint(f\"Total execution time: {execution_time}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nén thư mục checkpoints thành checkpoints.zip\n!zip -r checkpoints.zip checkpoints\n\n# Nén thư mục logs thành logs.zip\n!zip -r logs.zip logs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}