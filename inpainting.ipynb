{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12003148,"sourceType":"datasetVersion","datasetId":7550757},{"sourceId":12003359,"sourceType":"datasetVersion","datasetId":7550932},{"sourceId":12008765,"sourceType":"datasetVersion","datasetId":7554871},{"sourceId":12012380,"sourceType":"datasetVersion","datasetId":7557135},{"sourceId":12017358,"sourceType":"datasetVersion","datasetId":7560619},{"sourceId":12017393,"sourceType":"datasetVersion","datasetId":7560637},{"sourceId":12021536,"sourceType":"datasetVersion","datasetId":7563288}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile pix2pix_model.py\nimport os\nimport json\n\nimport numpy as np\nimport tensorflow as tf\nfrom datetime import datetime\n\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nfrom matplotlib import pyplot as plt\n\ndef define_discriminator(image_shape):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    \n    # ·∫£nh source\n    in_src_image = Input(shape=image_shape)  \n    # ·∫£nh target\n    in_target_image = Input(shape=image_shape) \n\n    # k·∫øt n·ªëi images, [256,256,6]\n    merged = Concatenate()([in_src_image, in_target_image])\n\n    # C64: 4x4 kernel Stride 2x2\n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C128: 4x4 kernel Stride 2x2\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C256: 4x4 kernel Stride 2x2\n    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C512: 4x4 kernel Stride 2x2\n    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # 4x4 kernel but Stride 1x1\n    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # patch output\n    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n    patch_out = Activation('sigmoid')(d)\n    # define model\n    model = Model([in_src_image, in_target_image], patch_out)\n    # compile model\n    opt = Adam(learning_rate=0.00005, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n    return model\n\ndef define_encoder_block(layer_in, n_filters, batchnorm=True):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # add downsampling layer\n    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    # conditionally add batch normalization\n    if batchnorm:\n        g = BatchNormalization()(g, training=True)\n    # leaky relu activation\n    g = LeakyReLU(alpha=0.2)(g)\n    return g\n\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # add upsampling layer\n    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    # add batch normalization\n    g = BatchNormalization()(g, training=True)\n    # conditionally add dropout\n    if dropout:\n        g = Dropout(0.5)(g, training=True)\n    # merge with skip connection\n    g = Concatenate()([g, skip_in])\n    # relu activation\n    g = Activation('relu')(g)\n    return g\n\ndef define_generator(image_shape=(256,256,3)):\n    # kh·ªüi t·∫°o tr·ªçng s·ªë\n    init = RandomNormal(stddev=0.02)\n    # ·∫£nh ƒë·∫ßu v√†o\n    in_image = Input(shape=image_shape)\n    # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n    e2 = define_encoder_block(e1, 128)\n    e3 = define_encoder_block(e2, 256)\n    e4 = define_encoder_block(e3, 512)\n    e5 = define_encoder_block(e4, 512)\n    e6 = define_encoder_block(e5, 512)\n    e7 = define_encoder_block(e6, 512)\n    # bottleneck, no batch norm and relu\n    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n    b = Activation('relu')(b)\n    # decoder model: CD512-CD512-CD512-C512-C256-C128-C64\n    d1 = decoder_block(b, e7, 512)\n    d2 = decoder_block(d1, e6, 512)\n    d3 = decoder_block(d2, e5, 512)\n    d4 = decoder_block(d3, e4, 512, dropout=False)\n    d5 = decoder_block(d4, e3, 256, dropout=False)\n    d6 = decoder_block(d5, e2, 128, dropout=False)\n    d7 = decoder_block(d6, e1, 64, dropout=False)\n    # output\n    g = Conv2DTranspose(image_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n    out_image = Activation('tanh')(g)\n    # define model\n    model = Model(in_image, out_image)\n    return model\n\ndef define_gan(g_model, d_model, image_shape):\n    # make weights in the discriminator not trainable\n    for layer in d_model.layers:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = False\n\n    # define the source image\n    in_src = Input(shape=image_shape)\n    # supply the image as input to the generator\n    gen_out = g_model(in_src)\n    # supply the input image and generated image as inputs to the discriminator\n    dis_out = d_model([in_src, gen_out])\n    # src image as input, generated image and disc. output as outputs\n    model = Model(in_src, [dis_out, gen_out])\n    # compile model\n    opt = Adam(learning_rate=0.00005, beta_1=0.5)\n    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n    return model\n\ndef generate_real_samples(src_batch, tar_batch, n_patch):\n    batch_size = len(src_batch)\n    # Create target \"real\" class labels (1s)\n    y = ones((batch_size, n_patch, n_patch, 1))\n    return [src_batch, tar_batch], y\n\ndef generate_fake_samples(g_model, src_batch, n_patch):\n    # generate fake instance\n    X = g_model.predict(src_batch, verbose=0)\n    # create 'fake' class labels (0)\n    y = zeros((len(X), n_patch, n_patch, 1))\n    return X, y\n\ndef summarize_performance(step, g_model, data_generator, n_samples=3):\n    \"\"\"\n    T√≥m t·∫Øt hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh b·∫±ng c√°ch t·∫°o v√† hi·ªÉn th·ªã ·∫£nh\n    \"\"\"\n    # L·∫•y m·ªôt batch ng·∫´u nhi√™n t·ª´ data generator\n    batch_idx = np.random.randint(0, len(data_generator))\n    src_batch, tar_batch = data_generator[batch_idx]\n    \n    # Ch·ªçn n_samples ·∫£nh ƒë·∫ßu ti√™n t·ª´ batch\n    n_samples = min(n_samples, src_batch.shape[0])\n    X_realA = src_batch[:n_samples]\n    X_realB = tar_batch[:n_samples]\n    \n    # T·∫°o ·∫£nh fake t·ª´ generator\n    X_fakeB = g_model.predict(X_realA, verbose=0)\n    \n    # Chu·∫©n h√≥a pixel values t·ª´ [-1,1] v·ªÅ [0,1] ƒë·ªÉ hi·ªÉn th·ªã\n    X_realA = (X_realA + 1) / 2.0\n    X_realB = (X_realB + 1) / 2.0\n    X_fakeB = (X_fakeB + 1) / 2.0\n    \n    # T·∫°o figure v·ªõi k√≠ch th∆∞·ªõc ph√π h·ª£p\n    plt.figure(figsize=(n_samples * 3, 9))\n    \n    # Hi·ªÉn th·ªã ·∫£nh source (h√†ng 1)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + i)\n        plt.axis('off')\n        plt.title('Source', fontsize=10)\n        if X_realA[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_realA[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_realA[i])\n    \n    # Hi·ªÉn th·ªã ·∫£nh generated (h√†ng 2)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples + i)\n        plt.axis('off')\n        plt.title('Generated', fontsize=10)\n        if X_fakeB[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_fakeB[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_fakeB[i])\n    \n    # Hi·ªÉn th·ªã ·∫£nh target th·ª±c (h√†ng 3)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n        plt.axis('off')\n        plt.title('Target', fontsize=10)\n        if X_realB[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_realB[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_realB[i])\n    \n    # ƒêi·ªÅu ch·ªânh layout v√† l∆∞u ·∫£nh\n    plt.tight_layout()\n    filename1 = 'plot_epoch_%03d.png' % ((step // len(data_generator)) + 1)\n    plt.savefig(filename1, dpi=150, bbox_inches='tight')\n    plt.close()\n    \n    # L∆∞u m√¥ h√¨nh generator\n    filename2 = 'g_model_epoch_%03d.h5' % ((step // len(data_generator)) + 1)\n    g_model.save(filename2)\n    \n    print(f'[INFO] Saved: {filename1} and {filename2}')\n\ndef train(d_model, g_model, gan_model, data_generator, n_epochs=100, checkpoint_dir='checkpoints'):\n    # t·∫°o th∆∞ m·ª•c checkpoint n·∫øu ch∆∞a c√≥\n    if not os.path.exists(checkpoint_dir):\n        os.makedirs(checkpoint_dir)\n        \n    # Create log directory for TensorBoard\n    log_dir = 'logs/20250529-102933'\n    summary_writer = tf.summary.create_file_writer(log_dir)\n    \n    # file l∆∞u tr·∫°ng th√°i epoch\n    checkpoint_file = os.path.join(checkpoint_dir, 'checkpoint.json')\n    start_epoch = 0\n    \n    # n·∫øu ƒë√£ c√≥ checkpoint tr∆∞·ªõc ƒë√≥, load l·∫°i\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            checkpoint = json.load(f)\n            start_epoch = checkpoint.get('epoch', 0)\n            print(f\"[INFO] Resuming from epoch {start_epoch + 1}\")\n            # load l·∫°i tr·ªçng s·ªë m√¥ h√¨nh\n            if os.path.exists(os.path.join(checkpoint_dir, 'd_model.weights.h5')):\n                d_model.load_weights(os.path.join(checkpoint_dir, 'd_model.weights.h5'))\n                g_model.load_weights(os.path.join(checkpoint_dir, 'g_model.weights.h5'))\n                gan_model.load_weights(os.path.join(checkpoint_dir, 'gan_model.weights.h5'))\n            \n    # l·∫•y chi·ªÅu cao trong discriminator (None, 16, 16, 1)\n    n_patch = d_model.output_shape[1]\n    # t√≠nh to√°n m·ªói batch trong epoch\n    bat_per_epo = len(data_generator)\n    \n    print(f\"[INFO] Starting training from epoch {start_epoch + 1}\")\n    print(f\"[INFO] Patch shape: {n_patch}\")\n    print(f\"[INFO] Batches per epoch: {bat_per_epo}\")\n\n    # enumerate epochs\n    for epoch in range(start_epoch, n_epochs):\n        # Shuffle data at start of epoch\n        data_generator.on_epoch_end()\n        \n        for batch in range(bat_per_epo):\n            # current step\n            step = epoch * bat_per_epo + batch + 1\n            # Get batch data t·ª´ generator\n            src_batch, tar_batch = data_generator[batch]\n\n            # Generate real samples\n            [X_realA, X_realB], y_real = generate_real_samples(src_batch, tar_batch, n_patch)\n            \n            # Generate fake samples\n            X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n            \n            # Update discriminator for real samples\n            d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n            \n            # Update discriminator for fake samples\n            d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n            \n            # Update generator\n            g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n            \n            print('STEP : %d, Epoch : %d, Batch : %d/%d,  Discriminator_real[%.3f] Discriminator_fake[%.3f] Generator[%.3f]' % (step, epoch+1, batch+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n            \n            # Ghi loss v√†o TensorBoard sau m·ªói step\n            with summary_writer.as_default():\n                tf.summary.scalar('Loss/Discriminator_real', d_loss1, step=step)\n                tf.summary.scalar('Loss/Discriminator_fake', d_loss2, step=step)\n                tf.summary.scalar('Loss/Generator', g_loss, step=step)\n                \n        # L∆∞u checkpoint sau m·ªói epoch\n        d_model.save_weights(os.path.join(checkpoint_dir, 'd_model.weights.h5'))\n        g_model.save_weights(os.path.join(checkpoint_dir, 'g_model.weights.h5'))\n        gan_model.save_weights(os.path.join(checkpoint_dir, 'gan_model.weights.h5'))\n        with open(checkpoint_file, 'w') as f:\n            json.dump({'epoch': epoch + 1}, f)\n            \n        # T√≥m t·∫Øt hi·ªáu su·∫•t m·ªói 10 epoch\n        if (epoch + 1) % 10 == 0:\n            summarize_performance(step, g_model, data_generator, n_samples=3)\n            \n    print(f\"[INFO] Training completed after {n_epochs} epochs\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from os import listdir\nfrom numpy import asarray, load\nfrom numpy import vstack\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nfrom matplotlib import pyplot\nimport numpy as np\nimport os\nfrom pix2pix_model import define_discriminator, define_generator, define_gan, train","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\nclass ImageDataGenerator(Sequence):\n    def __init__(self, sat_path, mask_path, batch_size=16, size=(256, 256), max_images=10000, shuffle=True):\n        self.sat_path = sat_path\n        self.mask_path = mask_path\n        self.batch_size = batch_size\n        self.size = size\n        self.max_images = max_images\n        self.shuffle = shuffle\n        \n        # L·∫•y danh s√°ch file t·ª´ c·∫£ 2 folder\n        sat_files = set(os.listdir(sat_path))\n        mask_files = set(os.listdir(mask_path))\n        \n        # Ch·ªâ l·∫•y c√°c file c√≥ trong c·∫£ 2 folder (intersection)\n        common_files = sat_files.intersection(mask_files)\n        self.image_files = [f for f in list(common_files)[:max_images] \n                           if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.tif', '.tiff'))]\n        \n        # T·∫°o indices cho shuffle\n        self.indices = np.arange(len(self.image_files))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n            \n        print(f\"Data Generator initialized:\")\n        print(f\"- Satellite images folder: {sat_path}\")\n        print(f\"- Mask images folder: {mask_path}\")\n        print(f\"- Common images found: {len(self.image_files)}\")\n        print(f\"- Total batches: {len(self)}\")\n        \n    def __len__(self):\n        return len(self.image_files) // self.batch_size\n    \n    def __getitem__(self, batch_idx):\n        # L·∫•y indices cho batch n√†y\n        start_idx = batch_idx * self.batch_size\n        end_idx = (batch_idx + 1) * self.batch_size\n        batch_indices = self.indices[start_idx:end_idx]\n        \n        sat_batch, mask_batch = [], []\n        \n        for idx in batch_indices:\n            filename = self.image_files[idx]\n            sat_path = os.path.join(self.sat_path, filename)\n            mask_path = os.path.join(self.mask_path, filename)\n            \n            try:\n                # Load satellite image\n                sat_img = load_img(sat_path, target_size=self.size)\n                sat_img = img_to_array(sat_img)\n                \n                # Load mask image\n                mask_img = load_img(mask_path, target_size=self.size)\n                mask_img = img_to_array(mask_img)\n                \n                sat_batch.append(sat_img)\n                mask_batch.append(mask_img)\n                \n            except Exception as e:\n                print(f\"Error loading {filename}: {e}\")\n                continue\n        \n        # Preprocess data (scale to [-1,1])\n        sat_batch = np.array(sat_batch)\n        mask_batch = np.array(mask_batch)\n        \n        sat_batch = (sat_batch - 127.5) / 127.5\n        mask_batch = (mask_batch - 127.5) / 127.5\n        \n        return sat_batch, mask_batch\n    \n    def on_epoch_end(self):\n        \"\"\"Shuffle data sau m·ªói epoch\"\"\"\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n    \n    def show_samples(self, num_samples=5):\n        \"\"\"Hi·ªÉn th·ªã m·ªôt s·ªë m·∫´u ·∫£nh satellite v√† mask t∆∞∆°ng ·ª©ng\"\"\"\n        # L·∫•y m·ªôt batch ƒë·ªÉ hi·ªÉn th·ªã\n        sat_batch, mask_batch = self.__getitem__(0)\n        \n        # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng samples hi·ªÉn th·ªã\n        num_samples = min(num_samples, len(sat_batch))\n        \n        fig, axes = plt.subplots(2, num_samples, figsize=(4*num_samples, 8))\n        if num_samples == 1:\n            axes = axes.reshape(2, 1)\n        \n        for i in range(num_samples):\n            # Chuy·ªÉn v·ªÅ scale [0,1] ƒë·ªÉ hi·ªÉn th·ªã\n            sat_display = (sat_batch[i] + 1) / 2\n            mask_display = (mask_batch[i] + 1) / 2\n            \n            # Hi·ªÉn th·ªã ·∫£nh satellite\n            axes[0, i].imshow(sat_display)\n            axes[0, i].set_title(f'Satellite {i+1}')\n            axes[0, i].axis('off')\n            \n            # Hi·ªÉn th·ªã ·∫£nh mask\n            axes[1, i].imshow(mask_display)\n            axes[1, i].set_title(f'Mask {i+1}')\n            axes[1, i].axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        return sat_batch, mask_batch\n\n\n# Kh·ªüi t·∫°o data generator v·ªõi ƒë∆∞·ªùng d·∫´n folder ri√™ng bi·ªát\ndata_generator = ImageDataGenerator(\n    sat_path='/kaggle/input/datapainting2/inpainting/mask',      \n    mask_path='/kaggle/input/datapainting2/inpainting/real',     \n    batch_size=16,\n    size=(256, 256),         # K√≠ch th∆∞·ªõc ·∫£nh\n    max_images=10000,\n    shuffle=True\n)\n\nprint(f\"Total batches: {len(data_generator)}\")\nprint(f\"Total images: {len(data_generator.image_files)}\")\n\n# Hi·ªÉn th·ªã m·ªôt s·ªë m·∫´u ·∫£nh ƒë·ªÉ ki·ªÉm tra\nprint(\"\\nHi·ªÉn th·ªã 5 m·∫´u ·∫£nh ƒë·∫ßu ti√™n:\")\nsample_sat, sample_mask = data_generator.show_samples(num_samples=5)\n\n# Ki·ªÉm tra shape c·ªßa data\nprint(f\"\\nShape c·ªßa satellite batch: {sample_sat.shape}\")\nprint(f\"Shape c·ªßa mask batch: {sample_mask.shape}\")\nprint(f\"Range c·ªßa satellite data: [{sample_sat.min():.3f}, {sample_sat.max():.3f}]\")\nprint(f\"Range c·ªßa mask data: [{sample_mask.min():.3f}, {sample_mask.max():.3f}]\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test load m·ªôt batch\ntry:\n    sample_src, sample_tar = data_generator[0]\n    print(f\"Source batch shape: {sample_src.shape}\")\n    print(f\"Target batch shape: {sample_tar.shape}\")\n    print(f\"Data range: [{sample_tar.min():.3f}, {sample_tar.max():.3f}]\")\n    \n    image_shape = sample_tar.shape[1:]  # (256, 256, 3)\n    print(f\"Image shape for model: {image_shape}\")\n    \nexcept Exception as e:\n    print(f\"Error testing generator: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Copy t·ª´ /kaggle/input/ v·ªÅ /kaggle/working n·∫øu c·∫ßn ghi th√™m\nimport shutil\nimport zipfile\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src = '/kaggle/input/tamthoi5/checkpoints/checkpoints'\ndst = '/kaggle/working/checkpoints'\n\nif not os.path.exists(dst):\n    shutil.copytree(src, dst)\n    print(\"‚úÖ ƒê√£ copy th∆∞ m·ª•c checkpoints t·ª´ input v√†o working\")\nelse:\n    print(\"üìÅ Th∆∞ m·ª•c checkpoints ƒë√£ t·ªìn t·∫°i trong working\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src = '/kaggle/input/tamthoi5/logs/logs'\ndst = '/kaggle/working/logs'\n\nif not os.path.exists(dst):\n    shutil.copytree(src, dst)\n    print(\"‚úÖ ƒê√£ copy th∆∞ m·ª•c logs t·ª´ input v√†o working\")\nelse:\n    print(\"üìÅ Th∆∞ m·ª•c logs ƒë√£ t·ªìn t·∫°i trong working\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\n# L·∫•y image shape t·ª´ m·ªôt batch ƒë·∫ßu ti√™n\nsample_src, sample_tar = data_generator[0]\nimage_shape = sample_src.shape[1:]  # (256, 256, 3)\n\n# Define models\nd_model = define_discriminator(image_shape)\ng_model = define_generator(image_shape)\ngan_model = define_gan(g_model, d_model, image_shape)\n\n# Training\nstart_time = datetime.now()\nprint(f\"Training started at: {start_time}\")\n\ntrain(d_model, g_model, gan_model, data_generator, \n      n_epochs=600, checkpoint_dir='/kaggle/working/checkpoints')\n\nend_time = datetime.now()\nexecution_time = end_time - start_time\nprint(f\"Training completed at: {end_time}\")\nprint(f\"Total execution time: {execution_time}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# N√©n th∆∞ m·ª•c checkpoints th√†nh checkpoints.zip\n!zip -r checkpoints.zip checkpoints\n\n# N√©n th∆∞ m·ª•c logs th√†nh logs.zip\n!zip -r logs.zip logs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}