{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"15cwemOwsDPbhqVhHSrNQnWaeR-POo1jU","authorship_tag":"ABX9TyOB414fzTOUkurQPx0oqG6w"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11883334,"sourceType":"datasetVersion","datasetId":7468650},{"sourceId":11910327,"sourceType":"datasetVersion","datasetId":7487617},{"sourceId":11910395,"sourceType":"datasetVersion","datasetId":7487664},{"sourceId":11910545,"sourceType":"datasetVersion","datasetId":7487757},{"sourceId":11910582,"sourceType":"datasetVersion","datasetId":7487781},{"sourceId":11945591,"sourceType":"datasetVersion","datasetId":7509696},{"sourceId":12018825,"sourceType":"datasetVersion","datasetId":7561609}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile pix2pix_model.py\nimport os\nimport json\n\nimport numpy as np\nimport tensorflow as tf\nfrom datetime import datetime\n\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nfrom matplotlib import pyplot as plt\n\ndef define_discriminator(image_shape):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    \n    # ·∫£nh source\n    in_src_image = Input(shape=image_shape)  \n    # ·∫£nh target\n    in_target_image = Input(shape=image_shape) \n\n    # k·∫øt n·ªëi images, [256,256,6]\n    merged = Concatenate()([in_src_image, in_target_image])\n\n    # C64: 4x4 kernel Stride 2x2\n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C128: 4x4 kernel Stride 2x2\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C256: 4x4 kernel Stride 2x2\n    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C512: 4x4 kernel Stride 2x2\n    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # 4x4 kernel but Stride 1x1\n    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # patch output\n    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n    patch_out = Activation('sigmoid')(d)\n    # define model\n    model = Model([in_src_image, in_target_image], patch_out)\n    # compile model\n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n    return model\n\ndef define_encoder_block(layer_in, n_filters, batchnorm=True):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # add downsampling layer\n    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    # conditionally add batch normalization\n    if batchnorm:\n        g = BatchNormalization()(g, training=True)\n    # leaky relu activation\n    g = LeakyReLU(alpha=0.2)(g)\n    return g\n\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # add upsampling layer\n    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    # add batch normalization\n    g = BatchNormalization()(g, training=True)\n    # conditionally add dropout\n    if dropout:\n        g = Dropout(0.5)(g, training=True)\n    # merge with skip connection\n    g = Concatenate()([g, skip_in])\n    # relu activation\n    g = Activation('relu')(g)\n    return g\n\ndef define_generator(image_shape=(256,256,3)):\n    # kh·ªüi t·∫°o tr·ªçng s·ªë\n    init = RandomNormal(stddev=0.02)\n    # ·∫£nh ƒë·∫ßu v√†o\n    in_image = Input(shape=image_shape)\n    # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n    e2 = define_encoder_block(e1, 128)\n    e3 = define_encoder_block(e2, 256)\n    e4 = define_encoder_block(e3, 512)\n    e5 = define_encoder_block(e4, 512)\n    e6 = define_encoder_block(e5, 512)\n    e7 = define_encoder_block(e6, 512)\n    # bottleneck, no batch norm and relu\n    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n    b = Activation('relu')(b)\n    # decoder model: CD512-CD512-CD512-C512-C256-C128-C64\n    d1 = decoder_block(b, e7, 512)\n    d2 = decoder_block(d1, e6, 512)\n    d3 = decoder_block(d2, e5, 512)\n    d4 = decoder_block(d3, e4, 512, dropout=False)\n    d5 = decoder_block(d4, e3, 256, dropout=False)\n    d6 = decoder_block(d5, e2, 128, dropout=False)\n    d7 = decoder_block(d6, e1, 64, dropout=False)\n    # output\n    g = Conv2DTranspose(image_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n    out_image = Activation('tanh')(g)\n    # define model\n    model = Model(in_image, out_image)\n    return model\n\ndef define_gan(g_model, d_model, image_shape):\n    # make weights in the discriminator not trainable\n    for layer in d_model.layers:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = False\n\n    # define the source image\n    in_src = Input(shape=image_shape)\n    # supply the image as input to the generator\n    gen_out = g_model(in_src)\n    # supply the input image and generated image as inputs to the discriminator\n    dis_out = d_model([in_src, gen_out])\n    # src image as input, generated image and disc. output as outputs\n    model = Model(in_src, [dis_out, gen_out])\n    # compile model\n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n    return model\n\ndef generate_real_samples(src_batch, tar_batch, n_patch):\n    batch_size = len(src_batch)\n    # Create target \"real\" class labels (1s)\n    y = ones((batch_size, n_patch, n_patch, 1))\n    return [src_batch, tar_batch], y\n\ndef generate_fake_samples(g_model, src_batch, n_patch):\n    # generate fake instance\n    X = g_model.predict(src_batch, verbose=0)\n    # create 'fake' class labels (0)\n    y = zeros((len(X), n_patch, n_patch, 1))\n    return X, y\n\ndef summarize_performance(step, g_model, data_generator, n_samples=3):\n    \"\"\"\n    T√≥m t·∫Øt hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh b·∫±ng c√°ch t·∫°o v√† hi·ªÉn th·ªã ·∫£nh\n    \"\"\"\n    # L·∫•y m·ªôt batch ng·∫´u nhi√™n t·ª´ data generator\n    batch_idx = np.random.randint(0, len(data_generator))\n    src_batch, tar_batch = data_generator[batch_idx]\n    \n    # Ch·ªçn n_samples ·∫£nh ƒë·∫ßu ti√™n t·ª´ batch\n    n_samples = min(n_samples, src_batch.shape[0])\n    X_realA = src_batch[:n_samples]\n    X_realB = tar_batch[:n_samples]\n    \n    # T·∫°o ·∫£nh fake t·ª´ generator\n    X_fakeB = g_model.predict(X_realA, verbose=0)\n    \n    # Chu·∫©n h√≥a pixel values t·ª´ [-1,1] v·ªÅ [0,1] ƒë·ªÉ hi·ªÉn th·ªã\n    X_realA = (X_realA + 1) / 2.0\n    X_realB = (X_realB + 1) / 2.0\n    X_fakeB = (X_fakeB + 1) / 2.0\n    \n    # T·∫°o figure v·ªõi k√≠ch th∆∞·ªõc ph√π h·ª£p\n    plt.figure(figsize=(n_samples * 3, 9))\n    \n    # Hi·ªÉn th·ªã ·∫£nh source (h√†ng 1)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + i)\n        plt.axis('off')\n        plt.title('Source', fontsize=10)\n        if X_realA[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_realA[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_realA[i])\n    \n    # Hi·ªÉn th·ªã ·∫£nh generated (h√†ng 2)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples + i)\n        plt.axis('off')\n        plt.title('Generated', fontsize=10)\n        if X_fakeB[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_fakeB[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_fakeB[i])\n    \n    # Hi·ªÉn th·ªã ·∫£nh target th·ª±c (h√†ng 3)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n        plt.axis('off')\n        plt.title('Target', fontsize=10)\n        if X_realB[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_realB[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_realB[i])\n    \n    # ƒêi·ªÅu ch·ªânh layout v√† l∆∞u ·∫£nh\n    plt.tight_layout()\n    filename1 = 'plot_epoch_%03d.png' % ((step // len(data_generator)) + 1)\n    plt.savefig(filename1, dpi=150, bbox_inches='tight')\n    plt.close()\n    \n    # L∆∞u m√¥ h√¨nh generator\n    filename2 = 'g_model_epoch_%03d.h5' % ((step // len(data_generator)) + 1)\n    g_model.save(filename2)\n    \n    print(f'[INFO] Saved: {filename1} and {filename2}')\n\ndef train(d_model, g_model, gan_model, data_generator, n_epochs=100, checkpoint_dir='checkpoints'):\n    # t·∫°o th∆∞ m·ª•c checkpoint n·∫øu ch∆∞a c√≥\n    if not os.path.exists(checkpoint_dir):\n        os.makedirs(checkpoint_dir)\n        \n    # Create log directory for TensorBoard\n    log_dir = f'logs/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n    summary_writer = tf.summary.create_file_writer(log_dir)\n    \n    # file l∆∞u tr·∫°ng th√°i epoch\n    checkpoint_file = os.path.join(checkpoint_dir, 'checkpoint.json')\n    start_epoch = 0\n    \n    # n·∫øu ƒë√£ c√≥ checkpoint tr∆∞·ªõc ƒë√≥, load l·∫°i\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            checkpoint = json.load(f)\n            start_epoch = checkpoint.get('epoch', 0)\n            print(f\"[INFO] Resuming from epoch {start_epoch + 1}\")\n            # load l·∫°i tr·ªçng s·ªë m√¥ h√¨nh\n            if os.path.exists(os.path.join(checkpoint_dir, 'd_model.weights.h5')):\n                d_model.load_weights(os.path.join(checkpoint_dir, 'd_model.weights.h5'))\n                g_model.load_weights(os.path.join(checkpoint_dir, 'g_model.weights.h5'))\n                gan_model.load_weights(os.path.join(checkpoint_dir, 'gan_model.weights.h5'))\n            \n    # l·∫•y chi·ªÅu cao trong discriminator (None, 16, 16, 1)\n    n_patch = d_model.output_shape[1]\n    # t√≠nh to√°n m·ªói batch trong epoch\n    bat_per_epo = len(data_generator)\n    \n    print(f\"[INFO] Starting training from epoch {start_epoch + 1}\")\n    print(f\"[INFO] Patch shape: {n_patch}\")\n    print(f\"[INFO] Batches per epoch: {bat_per_epo}\")\n\n    # enumerate epochs\n    for epoch in range(start_epoch, n_epochs):\n        # Shuffle data at start of epoch\n        data_generator.on_epoch_end()\n        \n        for batch in range(bat_per_epo):\n            # current step\n            step = epoch * bat_per_epo + batch + 1\n            # Get batch data t·ª´ generator\n            src_batch, tar_batch = data_generator[batch]\n\n            # Generate real samples\n            [X_realA, X_realB], y_real = generate_real_samples(src_batch, tar_batch, n_patch)\n            \n            # Generate fake samples\n            X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n            \n            # Update discriminator for real samples\n            d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n            \n            # Update discriminator for fake samples\n            d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n            \n            # Update generator\n            g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n            \n            print('STEP : %d, Epoch : %d, Batch : %d/%d,  Discriminator_real[%.3f] Discriminator_fake[%.3f] Generator[%.3f]' % (step, epoch+1, batch+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n            \n            # Ghi loss v√†o TensorBoard sau m·ªói step\n            with summary_writer.as_default():\n                tf.summary.scalar('Loss/Discriminator_real', d_loss1, step=step)\n                tf.summary.scalar('Loss/Discriminator_fake', d_loss2, step=step)\n                tf.summary.scalar('Loss/Generator', g_loss, step=step)\n                \n        # L∆∞u checkpoint sau m·ªói epoch\n        d_model.save_weights(os.path.join(checkpoint_dir, 'd_model.weights.h5'))\n        g_model.save_weights(os.path.join(checkpoint_dir, 'g_model.weights.h5'))\n        gan_model.save_weights(os.path.join(checkpoint_dir, 'gan_model.weights.h5'))\n        with open(checkpoint_file, 'w') as f:\n            json.dump({'epoch': epoch + 1}, f)\n            \n        # T√≥m t·∫Øt hi·ªáu su·∫•t m·ªói 10 epoch\n        if (epoch + 1) % 10 == 0:\n            summarize_performance(step, g_model, data_generator, n_samples=3)\n            \n    print(f\"[INFO] Training completed after {n_epochs} epochs\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## import th∆∞ vi·ªán\nfrom os import listdir\nfrom numpy import asarray, load\nfrom numpy import vstack\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nfrom matplotlib import pyplot\nimport numpy as np\nimport os\nfrom pix2pix_model import define_discriminator, define_generator, define_gan, train","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## kh·ªüi t·∫°o ImageDataGenerator\n\nfrom tensorflow.keras.utils import Sequence\n\nclass ImageDataGenerator(Sequence):\n    def __init__(self, path, batch_size=16, size=(256,512), max_images=10000, shuffle=True):\n        self.path = path\n        self.batch_size = batch_size\n        self.size = size\n        self.max_images = max_images\n        self.shuffle = shuffle\n        \n        # L·∫•y danh s√°ch file\n        all_files = os.listdir(path)\n        self.image_files = [f for f in all_files[:max_images] \n                           if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n        \n        # T·∫°o indices cho shuffle\n        self.indices = np.arange(len(self.image_files))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n            \n        print(f\"Data Generator initialized: {len(self.image_files)} images, {len(self)} batches\")\n        \n    def __len__(self):\n        return len(self.image_files) // self.batch_size\n    \n    def __getitem__(self, batch_idx):\n        # L·∫•y indices cho batch n√†y\n        start_idx = batch_idx * self.batch_size\n        end_idx = (batch_idx + 1) * self.batch_size\n        batch_indices = self.indices[start_idx:end_idx]\n        \n        src_batch, tar_batch = [], []\n        \n        for idx in batch_indices:\n            filename = self.image_files[idx]\n            full_path = os.path.join(self.path, filename)\n            \n            try:\n                # Load v√† resize ·∫£nh\n                pixels = load_img(full_path, target_size=self.size)\n                pixels = img_to_array(pixels)\n                \n                # Chia ·∫£nh th√†nh source v√† target\n                sat_img = pixels[:, :self.size[0], :]  # Left half\n                map_img = pixels[:, self.size[0]:, :]  # Right half\n                \n                src_batch.append(sat_img)\n                tar_batch.append(map_img)\n                \n            except Exception as e:\n                print(f\"Error loading {filename}: {e}\")\n                continue\n        \n        # Preprocess data (scale to [-1,1])\n        src_batch = np.array(src_batch)\n        tar_batch = np.array(tar_batch)\n        \n        src_batch = (src_batch - 127.5) / 127.5\n        tar_batch = (tar_batch - 127.5) / 127.5\n        \n        return src_batch, tar_batch\n    \n    def on_epoch_end(self):\n        \"\"\"Shuffle data sau m·ªói epoch\"\"\"\n        if self.shuffle:\n            np.random.shuffle(self.indices)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kh·ªüi t·∫°o data generator\ndata_generator = ImageDataGenerator(\n    path='/kaggle/input/edge2shoes/train',\n    batch_size=16,\n    size=(256, 512),  # height=256, width=512 (s·∫Ω ƒë∆∞·ª£c chia th√†nh 2 ·∫£nh 256x256)\n    max_images=50000,\n    shuffle=True\n)\nprint(f\"Total batches: {len(data_generator)}\")\nprint(f\"Total images: {len(data_generator.image_files)}\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test load m·ªôt batch\ntry:\n    sample_src, sample_tar = data_generator[0]\n    print(f\"Source batch shape: {sample_src.shape}\")\n    print(f\"Target batch shape: {sample_tar.shape}\")\n    print(f\"Data range: [{sample_src.min():.3f}, {sample_src.max():.3f}]\")\n    \n    image_shape = sample_src.shape[1:]  # (256, 256, 3)\n    print(f\"Image shape for model: {image_shape}\")\n    \nexcept Exception as e:\n    print(f\"Error testing generator: {e}\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Copy t·ª´ /kaggle/input/ v·ªÅ /kaggle/working n·∫øu c·∫ßn ghi th√™m\nimport shutil\nimport zipfile\nimport os\n\nsrc = '/kaggle/input/tamthoi1/checkpoints'\ndst = '/kaggle/working/checkpoints'\n\nif not os.path.exists(dst):\n    shutil.copytree(src, dst)\n    print(\"‚úÖ ƒê√£ copy th∆∞ m·ª•c checkpoints t·ª´ input v√†o working\")\nelse:\n    print(\"üìÅ Th∆∞ m·ª•c checkpoints ƒë√£ t·ªìn t·∫°i trong working\")\n\n# src = '/kaggle/input/total11/logs_50000_261/kaggle/working/logs'\n# dst = '/kaggle/working/logs'\n\n# if not os.path.exists(dst):\n#     shutil.copytree(src, dst)\n#     print(\"‚úÖ ƒê√£ copy th∆∞ m·ª•c logs t·ª´ input v√†o working\")\n# else:\n#     print(\"üìÅ Th∆∞ m·ª•c logs ƒë√£ t·ªìn t·∫°i trong working\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hu·∫•n luy·ªán \nfrom datetime import datetime\n# L·∫•y image shape t·ª´ m·ªôt batch ƒë·∫ßu ti√™n\nsample_src, sample_tar = data_generator[0]\nimage_shape = sample_src.shape[1:]  # (256, 256, 3)\n\n# Define models\nd_model = define_discriminator(image_shape)\ng_model = define_generator(image_shape)\ngan_model = define_gan(g_model, d_model, image_shape)\n\n# Training\nstart_time = datetime.now()\nprint(f\"Training started at: {start_time}\")\n\ntrain(d_model, g_model, gan_model, data_generator, \n      n_epochs=341, checkpoint_dir='/kaggle/working/checkpoints')\n\nend_time = datetime.now()\nexecution_time = end_time - start_time\nprint(f\"Training completed at: {end_time}\")\nprint(f\"Total execution time: {execution_time}\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#**KI·ªÇM TRA**","metadata":{}},{"cell_type":"markdown","source":"**X√≥a**","metadata":{}},{"cell_type":"code","source":"# logs_path = '/kaggle/working/logs'\n\n# if os.path.exists(logs_path):\n#     shutil.rmtree(logs_path)\n#     print(\"ƒê√£ x√≥a th∆∞ m·ª•c logs.\")\n# else:\n#     print(\"Th∆∞ m·ª•c logs kh√¥ng t·ªìn t·∫°i.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checkpoint_path = '/kaggle/working/checkpoints'\n\n# # Ki·ªÉm tra xem th∆∞ m·ª•c c√≥ t·ªìn t·∫°i kh√¥ng, n·∫øu c√≥ th√¨ x√≥a\n# if os.path.exists(checkpoint_path):\n#     shutil.rmtree(checkpoint_path)\n#     print(\"‚úÖ ƒê√£ x√≥a th∆∞ m·ª•c 'checkpoints'\")\n# else:\n#     print(\"‚ùå Th∆∞ m·ª•c 'checkpoints' kh√¥ng t·ªìn t·∫°i\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(os.listdir('/kaggle/working'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(os.listdir('/kaggle/input/aaaaaa'))\n# print(os.listdir('/kaggle/input/aaaaaa/checkpoints/kaggle/working/checkpoints'))\n# print(os.listdir('/kaggle/input/aaaaaa/logs/kaggle/working/logs/20250521-114829'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Li·ªát k√™ file trong th∆∞ m·ª•c checkpoints\n# print(\"üìÇ File trong checkpoints:\")\n# print(os.listdir('/kaggle/working/checkpoints'))\n\n# # Li·ªát k√™ file trong th∆∞ m·ª•c logs\n# print(\"\\nüìÇ File trong logs:\")\n# print(os.listdir('/kaggle/working/logs'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Test trained model on a few images...\n\n# from keras.models import load_model\n# from numpy.random import randint","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = load_model('/kaggle/input/sladkjasl/keras/default/1/model_420001.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # plot source, generated and target images\n# def plot_images(src_img, gen_img, tar_img):\n# \timages = vstack((src_img, gen_img, tar_img))\n# \t# scale from [-1,1] to [0,1]\n# \timages = (images + 1) / 2.0\n# \ttitles = ['Source', 'Generated', 'Expected']\n# \t# plot images row by row\n# \tfor i in range(len(images)):\n# \t\t# define subplot\n# \t\tpyplot.subplot(1, 3, 1 + i)\n# \t\t# turn off axis\n# \t\tpyplot.axis('off')\n# \t\t# plot raw pixel data\n# \t\tpyplot.imshow(images[i])\n# \t\t# show title\n# \t\tpyplot.title(titles[i])\n# \tpyplot.show()\n\n\n\n# [X1, X2] = dataset\n# # select random example\n# ix = randint(0, len(X1), 1)\n# src_image, tar_image = X1[ix], X2[ix]\n# # generate image from source\n# gen_image = model.predict(src_image)\n# # plot all three images\n# plot_images(src_image, gen_image, tar_image)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # === B∆Ø·ªöC 1: Load v√† x·ª≠ l√Ω ·∫£nh ===\n# import numpy as np\n# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n# from matplotlib import pyplot\n# from numpy import vstack\n\n# sizev2 = (256, 512)\n# img = load_img('/kaggle/input/testshoes/val/121_AB.jpg', target_size=sizev2)  # ·∫¢nh gh√©p 2 ph·∫ßn\n# pixelsv2 = img_to_array(img)\n\n# # C·∫Øt ·∫£nh: ·∫£nh b√™n tr√°i l√† input, ·∫£nh b√™n ph·∫£i l√† ground truth\n# src = pixelsv2[:, :sizev2[0], :]   # (256, 256, 3)\n# tar = pixelsv2[:, sizev2[0]:, :]   # (256, 256, 3)\n# datav2 = [src, tar]\n\n# def preprocess_data(data):\n#     # load compressed arrays\n#     # unpack arrays\n#     X1, X2 = data[0], data[1]\n#     # scale from [0,255] to [-1,1]\n#     X1 = (X1 - 127.5) / 127.5\n#     X2 = (X2 - 127.5) / 127.5\n#     return [X1, X2]\n\n# datasetv2 = preprocess_data(datav2)\n\n# # plot source, generated and target images\n# def plot_images(src, gen, tar):\n#     # ƒê·∫£m b·∫£o d·ªØ li·ªáu c√≥ ƒë√∫ng shape v√† ki·ªÉu\n#     images = [src, gen, tar]\n#     titles = ['Source', 'Generated', 'Expected']\n    \n#     # T·∫°o figure v·ªõi k√≠ch th∆∞·ªõc ph√π h·ª£p\n#     pyplot.figure(figsize=(15, 5))\n    \n#     # plot images row by row\n#     for i in range(len(images)):\n#         # define subplot (1 h√†ng, 3 c·ªôt, subplot th·ª© i+1)\n#         pyplot.subplot(1, 3, i + 1)\n#         # turn off axis\n#         pyplot.axis('off')\n        \n#         # Scale t·ª´ [-1,1] v·ªÅ [0,1] cho t·ª´ng ·∫£nh\n#         img_scaled = (images[i] + 1) / 2.0\n#         # ƒê·∫£m b·∫£o gi√° tr·ªã trong kho·∫£ng [0,1]\n#         img_scaled = np.clip(img_scaled, 0, 1)\n        \n#         # plot raw pixel data\n#         pyplot.imshow(img_scaled)\n#         # show title\n#         pyplot.title(titles[i])\n    \n#     pyplot.tight_layout()\n#     pyplot.show()\n\n# [X1, X2] = datasetv2\n# src, tar = X1, X2\n\n# # === PH·∫¶N S·ª¨A L·ªñI: Th√™m batch dimension ===\n# # Chuy·ªÉn t·ª´ shape (256, 256, 3) th√†nh (1, 256, 256, 3)\n# src_batch = np.expand_dims(src, axis=0)\n\n# # generate image from source\n# gen_batch = model.predict(src_batch)\n\n# # Lo·∫°i b·ªè batch dimension ƒë·ªÉ v·ªÅ l·∫°i shape (256, 256, 3)\n# gen = np.squeeze(gen_batch, axis=0)\n\n# # plot all three images\n# plot_images(src, gen, tar)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# # === Load v√† x·ª≠ l√Ω ·∫£nh source ===\n# img = load_img('/kaggle/input/aaaaasde/test2.png', target_size=(256, 256))\n# img_array = img_to_array(img)\n\n# print(f\"Original image range: [{img_array.min():.2f}, {img_array.max():.2f}]\")\n# print(f\"Original image shape: {img_array.shape}\")\n\n# # Scale t·ª´ [0,255] v·ªÅ [-1,1] gi·ªëng l√∫c train\n# img_array = (img_array - 127.5) / 127.5\n# print(f\"Normalized image range: [{img_array.min():.2f}, {img_array.max():.2f}]\")\n\n# # Th√™m batch dimension\n# src_image = np.expand_dims(img_array, axis=0)  # (1, 256, 256, 3)\n\n# # === D·ª± ƒëo√°n ===\n# gen_image = model.predict(src_image, verbose=0)\n# print(f\"Generated image range: [{gen_image.min():.2f}, {gen_image.max():.2f}]\")\n\n# # === V·∫Ω ·∫£nh Source v√† Generated ===\n# def plot_images_debug(src_img, gen_img):\n#     # scale t·ª´ [-1,1] v·ªÅ [0,1] ƒë·ªÉ hi·ªÉn th·ªã\n#     src_display = (src_img + 1) / 2.0\n#     gen_display = (gen_img + 1) / 2.0\n    \n#     # Clip ƒë·ªÉ ƒë·∫£m b·∫£o trong kho·∫£ng [0,1]\n#     src_display = np.clip(src_display, 0, 1)\n#     gen_display = np.clip(gen_display, 0, 1)\n    \n#     images = [src_display[0], gen_display[0]]\n#     titles = ['Source', 'Generated']\n    \n#     plt.figure(figsize=(12, 6))\n#     for i in range(2):\n#         plt.subplot(1, 2, i + 1)\n#         plt.axis('off')\n#         plt.title(titles[i])\n#         plt.imshow(images[i])\n        \n#         # Th√™m th√¥ng tin v·ªÅ range\n#         img_min, img_max = images[i].min(), images[i].max()\n#         plt.xlabel(f'Range: [{img_min:.3f}, {img_max:.3f}]')\n    \n#     plt.tight_layout()\n#     plt.show()\n\n# plot_images_debug(src_image, gen_image)\n\n# # === Th√™m histogram ƒë·ªÉ so s√°nh ph√¢n ph·ªëi ===\n# def plot_histograms(src_img, gen_img):\n#     plt.figure(figsize=(12, 4))\n    \n#     # Histogram c·ªßa source image\n#     plt.subplot(1, 2, 1)\n#     plt.hist(src_img.flatten(), bins=50, alpha=0.7, color='blue')\n#     plt.title('Source Image Histogram')\n#     plt.xlabel('Pixel Value')\n#     plt.ylabel('Frequency')\n    \n#     # Histogram c·ªßa generated image\n#     plt.subplot(1, 2, 2)\n#     plt.hist(gen_img.flatten(), bins=50, alpha=0.7, color='red')\n#     plt.title('Generated Image Histogram')\n#     plt.xlabel('Pixel Value')\n#     plt.ylabel('Frequency')\n    \n#     plt.tight_layout()\n#     plt.show()\n\n# plot_histograms(src_image, gen_image)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/checkpoints.zip /kaggle/working/checkpoints\n!zip -r /kaggle/working/logs.zip /kaggle/working/logs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shutil\n\n# # Copy file checkpoint\n# shutil.copy('/kaggle/working/checkpoints/d_model.weights.h5', '/kaggle/working/d_model.weights.h5')\n# shutil.copy('/kaggle/working/checkpoints/g_model.weights.h5', '/kaggle/working/g_model.weights.h5')\n# shutil.copy('/kaggle/working/checkpoints/gan_model.weights.h5', '/kaggle/working/gan_model.weights.h5')\n# shutil.copy('/kaggle/working/checkpoints/checkpoint.json', '/kaggle/working/checkpoint.json')\n\n# # Copy file logs\n# shutil.copytree('/kaggle/working/logs/20250521-114829', '/kaggle/working/logs_copy')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tensorboard --logdir=\"D:\\AI\\kaggle\\working\\logs\\20250521-114829\"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}