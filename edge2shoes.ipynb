{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"15cwemOwsDPbhqVhHSrNQnWaeR-POo1jU","authorship_tag":"ABX9TyOB414fzTOUkurQPx0oqG6w"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11883334,"sourceType":"datasetVersion","datasetId":7468650},{"sourceId":11910327,"sourceType":"datasetVersion","datasetId":7487617},{"sourceId":11910395,"sourceType":"datasetVersion","datasetId":7487664},{"sourceId":11910545,"sourceType":"datasetVersion","datasetId":7487757},{"sourceId":11910582,"sourceType":"datasetVersion","datasetId":7487781},{"sourceId":11945591,"sourceType":"datasetVersion","datasetId":7509696},{"sourceId":12018825,"sourceType":"datasetVersion","datasetId":7561609}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile pix2pix_model.py\nimport os\nimport json\n\nimport numpy as np\nimport tensorflow as tf\nfrom datetime import datetime\n\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nfrom matplotlib import pyplot as plt\n\ndef define_discriminator(image_shape):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    \n    # ảnh source\n    in_src_image = Input(shape=image_shape)  \n    # ảnh target\n    in_target_image = Input(shape=image_shape) \n\n    # kết nối images, [256,256,6]\n    merged = Concatenate()([in_src_image, in_target_image])\n\n    # C64: 4x4 kernel Stride 2x2\n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C128: 4x4 kernel Stride 2x2\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C256: 4x4 kernel Stride 2x2\n    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # C512: 4x4 kernel Stride 2x2\n    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # 4x4 kernel but Stride 1x1\n    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # patch output\n    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n    patch_out = Activation('sigmoid')(d)\n    # define model\n    model = Model([in_src_image, in_target_image], patch_out)\n    # compile model\n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n    return model\n\ndef define_encoder_block(layer_in, n_filters, batchnorm=True):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # add downsampling layer\n    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    # conditionally add batch normalization\n    if batchnorm:\n        g = BatchNormalization()(g, training=True)\n    # leaky relu activation\n    g = LeakyReLU(alpha=0.2)(g)\n    return g\n\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # add upsampling layer\n    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    # add batch normalization\n    g = BatchNormalization()(g, training=True)\n    # conditionally add dropout\n    if dropout:\n        g = Dropout(0.5)(g, training=True)\n    # merge with skip connection\n    g = Concatenate()([g, skip_in])\n    # relu activation\n    g = Activation('relu')(g)\n    return g\n\ndef define_generator(image_shape=(256,256,3)):\n    # khởi tạo trọng số\n    init = RandomNormal(stddev=0.02)\n    # ảnh đầu vào\n    in_image = Input(shape=image_shape)\n    # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n    e2 = define_encoder_block(e1, 128)\n    e3 = define_encoder_block(e2, 256)\n    e4 = define_encoder_block(e3, 512)\n    e5 = define_encoder_block(e4, 512)\n    e6 = define_encoder_block(e5, 512)\n    e7 = define_encoder_block(e6, 512)\n    # bottleneck, no batch norm and relu\n    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n    b = Activation('relu')(b)\n    # decoder model: CD512-CD512-CD512-C512-C256-C128-C64\n    d1 = decoder_block(b, e7, 512)\n    d2 = decoder_block(d1, e6, 512)\n    d3 = decoder_block(d2, e5, 512)\n    d4 = decoder_block(d3, e4, 512, dropout=False)\n    d5 = decoder_block(d4, e3, 256, dropout=False)\n    d6 = decoder_block(d5, e2, 128, dropout=False)\n    d7 = decoder_block(d6, e1, 64, dropout=False)\n    # output\n    g = Conv2DTranspose(image_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n    out_image = Activation('tanh')(g)\n    # define model\n    model = Model(in_image, out_image)\n    return model\n\ndef define_gan(g_model, d_model, image_shape):\n    # make weights in the discriminator not trainable\n    for layer in d_model.layers:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = False\n\n    # define the source image\n    in_src = Input(shape=image_shape)\n    # supply the image as input to the generator\n    gen_out = g_model(in_src)\n    # supply the input image and generated image as inputs to the discriminator\n    dis_out = d_model([in_src, gen_out])\n    # src image as input, generated image and disc. output as outputs\n    model = Model(in_src, [dis_out, gen_out])\n    # compile model\n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n    return model\n\ndef generate_real_samples(src_batch, tar_batch, n_patch):\n    batch_size = len(src_batch)\n    # Create target \"real\" class labels (1s)\n    y = ones((batch_size, n_patch, n_patch, 1))\n    return [src_batch, tar_batch], y\n\ndef generate_fake_samples(g_model, src_batch, n_patch):\n    # generate fake instance\n    X = g_model.predict(src_batch, verbose=0)\n    # create 'fake' class labels (0)\n    y = zeros((len(X), n_patch, n_patch, 1))\n    return X, y\n\ndef summarize_performance(step, g_model, data_generator, n_samples=3):\n    \"\"\"\n    Tóm tắt hiệu suất của mô hình bằng cách tạo và hiển thị ảnh\n    \"\"\"\n    # Lấy một batch ngẫu nhiên từ data generator\n    batch_idx = np.random.randint(0, len(data_generator))\n    src_batch, tar_batch = data_generator[batch_idx]\n    \n    # Chọn n_samples ảnh đầu tiên từ batch\n    n_samples = min(n_samples, src_batch.shape[0])\n    X_realA = src_batch[:n_samples]\n    X_realB = tar_batch[:n_samples]\n    \n    # Tạo ảnh fake từ generator\n    X_fakeB = g_model.predict(X_realA, verbose=0)\n    \n    # Chuẩn hóa pixel values từ [-1,1] về [0,1] để hiển thị\n    X_realA = (X_realA + 1) / 2.0\n    X_realB = (X_realB + 1) / 2.0\n    X_fakeB = (X_fakeB + 1) / 2.0\n    \n    # Tạo figure với kích thước phù hợp\n    plt.figure(figsize=(n_samples * 3, 9))\n    \n    # Hiển thị ảnh source (hàng 1)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + i)\n        plt.axis('off')\n        plt.title('Source', fontsize=10)\n        if X_realA[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_realA[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_realA[i])\n    \n    # Hiển thị ảnh generated (hàng 2)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples + i)\n        plt.axis('off')\n        plt.title('Generated', fontsize=10)\n        if X_fakeB[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_fakeB[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_fakeB[i])\n    \n    # Hiển thị ảnh target thực (hàng 3)\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n        plt.axis('off')\n        plt.title('Target', fontsize=10)\n        if X_realB[i].shape[-1] == 1:  # Grayscale\n            plt.imshow(X_realB[i].squeeze(), cmap='gray')\n        else:  # RGB\n            plt.imshow(X_realB[i])\n    \n    # Điều chỉnh layout và lưu ảnh\n    plt.tight_layout()\n    filename1 = 'plot_epoch_%03d.png' % ((step // len(data_generator)) + 1)\n    plt.savefig(filename1, dpi=150, bbox_inches='tight')\n    plt.close()\n    \n    # Lưu mô hình generator\n    filename2 = 'g_model_epoch_%03d.h5' % ((step // len(data_generator)) + 1)\n    g_model.save(filename2)\n    \n    print(f'[INFO] Saved: {filename1} and {filename2}')\n\ndef train(d_model, g_model, gan_model, data_generator, n_epochs=100, checkpoint_dir='checkpoints'):\n    # tạo thư mục checkpoint nếu chưa có\n    if not os.path.exists(checkpoint_dir):\n        os.makedirs(checkpoint_dir)\n        \n    # Create log directory for TensorBoard\n    log_dir = f'logs/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n    summary_writer = tf.summary.create_file_writer(log_dir)\n    \n    # file lưu trạng thái epoch\n    checkpoint_file = os.path.join(checkpoint_dir, 'checkpoint.json')\n    start_epoch = 0\n    \n    # nếu đã có checkpoint trước đó, load lại\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            checkpoint = json.load(f)\n            start_epoch = checkpoint.get('epoch', 0)\n            print(f\"[INFO] Resuming from epoch {start_epoch + 1}\")\n            # load lại trọng số mô hình\n            if os.path.exists(os.path.join(checkpoint_dir, 'd_model.weights.h5')):\n                d_model.load_weights(os.path.join(checkpoint_dir, 'd_model.weights.h5'))\n                g_model.load_weights(os.path.join(checkpoint_dir, 'g_model.weights.h5'))\n                gan_model.load_weights(os.path.join(checkpoint_dir, 'gan_model.weights.h5'))\n            \n    # lấy chiều cao trong discriminator (None, 16, 16, 1)\n    n_patch = d_model.output_shape[1]\n    # tính toán mỗi batch trong epoch\n    bat_per_epo = len(data_generator)\n    \n    print(f\"[INFO] Starting training from epoch {start_epoch + 1}\")\n    print(f\"[INFO] Patch shape: {n_patch}\")\n    print(f\"[INFO] Batches per epoch: {bat_per_epo}\")\n\n    # enumerate epochs\n    for epoch in range(start_epoch, n_epochs):\n        # Shuffle data at start of epoch\n        data_generator.on_epoch_end()\n        \n        for batch in range(bat_per_epo):\n            # current step\n            step = epoch * bat_per_epo + batch + 1\n            # Get batch data từ generator\n            src_batch, tar_batch = data_generator[batch]\n\n            # Generate real samples\n            [X_realA, X_realB], y_real = generate_real_samples(src_batch, tar_batch, n_patch)\n            \n            # Generate fake samples\n            X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n            \n            # Update discriminator for real samples\n            d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n            \n            # Update discriminator for fake samples\n            d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n            \n            # Update generator\n            g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n            \n            print('STEP : %d, Epoch : %d, Batch : %d/%d,  Discriminator_real[%.3f] Discriminator_fake[%.3f] Generator[%.3f]' % (step, epoch+1, batch+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n            \n            # Ghi loss vào TensorBoard sau mỗi step\n            with summary_writer.as_default():\n                tf.summary.scalar('Loss/Discriminator_real', d_loss1, step=step)\n                tf.summary.scalar('Loss/Discriminator_fake', d_loss2, step=step)\n                tf.summary.scalar('Loss/Generator', g_loss, step=step)\n                \n        # Lưu checkpoint sau mỗi epoch\n        d_model.save_weights(os.path.join(checkpoint_dir, 'd_model.weights.h5'))\n        g_model.save_weights(os.path.join(checkpoint_dir, 'g_model.weights.h5'))\n        gan_model.save_weights(os.path.join(checkpoint_dir, 'gan_model.weights.h5'))\n        with open(checkpoint_file, 'w') as f:\n            json.dump({'epoch': epoch + 1}, f)\n            \n        # Tóm tắt hiệu suất mỗi 10 epoch\n        if (epoch + 1) % 10 == 0:\n            summarize_performance(step, g_model, data_generator, n_samples=3)\n            \n    print(f\"[INFO] Training completed after {n_epochs} epochs\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## import thư viện\nfrom os import listdir\nfrom numpy import asarray, load\nfrom numpy import vstack\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nfrom matplotlib import pyplot\nimport numpy as np\nimport os\nfrom pix2pix_model import define_discriminator, define_generator, define_gan, train","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## khởi tạo ImageDataGenerator\n\nfrom tensorflow.keras.utils import Sequence\n\nclass ImageDataGenerator(Sequence):\n    def __init__(self, path, batch_size=16, size=(256,512), max_images=10000, shuffle=True):\n        self.path = path\n        self.batch_size = batch_size\n        self.size = size\n        self.max_images = max_images\n        self.shuffle = shuffle\n        \n        # Lấy danh sách file\n        all_files = os.listdir(path)\n        self.image_files = [f for f in all_files[:max_images] \n                           if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n        \n        # Tạo indices cho shuffle\n        self.indices = np.arange(len(self.image_files))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n            \n        print(f\"Data Generator initialized: {len(self.image_files)} images, {len(self)} batches\")\n        \n    def __len__(self):\n        return len(self.image_files) // self.batch_size\n    \n    def __getitem__(self, batch_idx):\n        # Lấy indices cho batch này\n        start_idx = batch_idx * self.batch_size\n        end_idx = (batch_idx + 1) * self.batch_size\n        batch_indices = self.indices[start_idx:end_idx]\n        \n        src_batch, tar_batch = [], []\n        \n        for idx in batch_indices:\n            filename = self.image_files[idx]\n            full_path = os.path.join(self.path, filename)\n            \n            try:\n                # Load và resize ảnh\n                pixels = load_img(full_path, target_size=self.size)\n                pixels = img_to_array(pixels)\n                \n                # Chia ảnh thành source và target\n                sat_img = pixels[:, :self.size[0], :]  # Left half\n                map_img = pixels[:, self.size[0]:, :]  # Right half\n                \n                src_batch.append(sat_img)\n                tar_batch.append(map_img)\n                \n            except Exception as e:\n                print(f\"Error loading {filename}: {e}\")\n                continue\n        \n        # Preprocess data (scale to [-1,1])\n        src_batch = np.array(src_batch)\n        tar_batch = np.array(tar_batch)\n        \n        src_batch = (src_batch - 127.5) / 127.5\n        tar_batch = (tar_batch - 127.5) / 127.5\n        \n        return src_batch, tar_batch\n    \n    def on_epoch_end(self):\n        \"\"\"Shuffle data sau mỗi epoch\"\"\"\n        if self.shuffle:\n            np.random.shuffle(self.indices)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Khởi tạo data generator\ndata_generator = ImageDataGenerator(\n    path='/kaggle/input/edge2shoes/train',\n    batch_size=16,\n    size=(256, 512),  # height=256, width=512 (sẽ được chia thành 2 ảnh 256x256)\n    max_images=50000,\n    shuffle=True\n)\nprint(f\"Total batches: {len(data_generator)}\")\nprint(f\"Total images: {len(data_generator.image_files)}\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test load một batch\ntry:\n    sample_src, sample_tar = data_generator[0]\n    print(f\"Source batch shape: {sample_src.shape}\")\n    print(f\"Target batch shape: {sample_tar.shape}\")\n    print(f\"Data range: [{sample_src.min():.3f}, {sample_src.max():.3f}]\")\n    \n    image_shape = sample_src.shape[1:]  # (256, 256, 3)\n    print(f\"Image shape for model: {image_shape}\")\n    \nexcept Exception as e:\n    print(f\"Error testing generator: {e}\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Copy từ /kaggle/input/ về /kaggle/working nếu cần ghi thêm\nimport shutil\nimport zipfile\nimport os\n\nsrc = '/kaggle/input/tamthoi1/checkpoints'\ndst = '/kaggle/working/checkpoints'\n\nif not os.path.exists(dst):\n    shutil.copytree(src, dst)\n    print(\"✅ Đã copy thư mục checkpoints từ input vào working\")\nelse:\n    print(\"📁 Thư mục checkpoints đã tồn tại trong working\")\n\n# src = '/kaggle/input/total11/logs_50000_261/kaggle/working/logs'\n# dst = '/kaggle/working/logs'\n\n# if not os.path.exists(dst):\n#     shutil.copytree(src, dst)\n#     print(\"✅ Đã copy thư mục logs từ input vào working\")\n# else:\n#     print(\"📁 Thư mục logs đã tồn tại trong working\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# huấn luyện \nfrom datetime import datetime\n# Lấy image shape từ một batch đầu tiên\nsample_src, sample_tar = data_generator[0]\nimage_shape = sample_src.shape[1:]  # (256, 256, 3)\n\n# Define models\nd_model = define_discriminator(image_shape)\ng_model = define_generator(image_shape)\ngan_model = define_gan(g_model, d_model, image_shape)\n\n# Training\nstart_time = datetime.now()\nprint(f\"Training started at: {start_time}\")\n\ntrain(d_model, g_model, gan_model, data_generator, \n      n_epochs=341, checkpoint_dir='/kaggle/working/checkpoints')\n\nend_time = datetime.now()\nexecution_time = end_time - start_time\nprint(f\"Training completed at: {end_time}\")\nprint(f\"Total execution time: {execution_time}\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#**KIỂM TRA**","metadata":{}},{"cell_type":"markdown","source":"**Xóa**","metadata":{}},{"cell_type":"code","source":"# logs_path = '/kaggle/working/logs'\n\n# if os.path.exists(logs_path):\n#     shutil.rmtree(logs_path)\n#     print(\"Đã xóa thư mục logs.\")\n# else:\n#     print(\"Thư mục logs không tồn tại.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checkpoint_path = '/kaggle/working/checkpoints'\n\n# # Kiểm tra xem thư mục có tồn tại không, nếu có thì xóa\n# if os.path.exists(checkpoint_path):\n#     shutil.rmtree(checkpoint_path)\n#     print(\"✅ Đã xóa thư mục 'checkpoints'\")\n# else:\n#     print(\"❌ Thư mục 'checkpoints' không tồn tại\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(os.listdir('/kaggle/working'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(os.listdir('/kaggle/input/aaaaaa'))\n# print(os.listdir('/kaggle/input/aaaaaa/checkpoints/kaggle/working/checkpoints'))\n# print(os.listdir('/kaggle/input/aaaaaa/logs/kaggle/working/logs/20250521-114829'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Liệt kê file trong thư mục checkpoints\n# print(\"📂 File trong checkpoints:\")\n# print(os.listdir('/kaggle/working/checkpoints'))\n\n# # Liệt kê file trong thư mục logs\n# print(\"\\n📂 File trong logs:\")\n# print(os.listdir('/kaggle/working/logs'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Test trained model on a few images...\n\n# from keras.models import load_model\n# from numpy.random import randint","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = load_model('/kaggle/input/sladkjasl/keras/default/1/model_420001.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # plot source, generated and target images\n# def plot_images(src_img, gen_img, tar_img):\n# \timages = vstack((src_img, gen_img, tar_img))\n# \t# scale from [-1,1] to [0,1]\n# \timages = (images + 1) / 2.0\n# \ttitles = ['Source', 'Generated', 'Expected']\n# \t# plot images row by row\n# \tfor i in range(len(images)):\n# \t\t# define subplot\n# \t\tpyplot.subplot(1, 3, 1 + i)\n# \t\t# turn off axis\n# \t\tpyplot.axis('off')\n# \t\t# plot raw pixel data\n# \t\tpyplot.imshow(images[i])\n# \t\t# show title\n# \t\tpyplot.title(titles[i])\n# \tpyplot.show()\n\n\n\n# [X1, X2] = dataset\n# # select random example\n# ix = randint(0, len(X1), 1)\n# src_image, tar_image = X1[ix], X2[ix]\n# # generate image from source\n# gen_image = model.predict(src_image)\n# # plot all three images\n# plot_images(src_image, gen_image, tar_image)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # === BƯỚC 1: Load và xử lý ảnh ===\n# import numpy as np\n# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n# from matplotlib import pyplot\n# from numpy import vstack\n\n# sizev2 = (256, 512)\n# img = load_img('/kaggle/input/testshoes/val/121_AB.jpg', target_size=sizev2)  # Ảnh ghép 2 phần\n# pixelsv2 = img_to_array(img)\n\n# # Cắt ảnh: ảnh bên trái là input, ảnh bên phải là ground truth\n# src = pixelsv2[:, :sizev2[0], :]   # (256, 256, 3)\n# tar = pixelsv2[:, sizev2[0]:, :]   # (256, 256, 3)\n# datav2 = [src, tar]\n\n# def preprocess_data(data):\n#     # load compressed arrays\n#     # unpack arrays\n#     X1, X2 = data[0], data[1]\n#     # scale from [0,255] to [-1,1]\n#     X1 = (X1 - 127.5) / 127.5\n#     X2 = (X2 - 127.5) / 127.5\n#     return [X1, X2]\n\n# datasetv2 = preprocess_data(datav2)\n\n# # plot source, generated and target images\n# def plot_images(src, gen, tar):\n#     # Đảm bảo dữ liệu có đúng shape và kiểu\n#     images = [src, gen, tar]\n#     titles = ['Source', 'Generated', 'Expected']\n    \n#     # Tạo figure với kích thước phù hợp\n#     pyplot.figure(figsize=(15, 5))\n    \n#     # plot images row by row\n#     for i in range(len(images)):\n#         # define subplot (1 hàng, 3 cột, subplot thứ i+1)\n#         pyplot.subplot(1, 3, i + 1)\n#         # turn off axis\n#         pyplot.axis('off')\n        \n#         # Scale từ [-1,1] về [0,1] cho từng ảnh\n#         img_scaled = (images[i] + 1) / 2.0\n#         # Đảm bảo giá trị trong khoảng [0,1]\n#         img_scaled = np.clip(img_scaled, 0, 1)\n        \n#         # plot raw pixel data\n#         pyplot.imshow(img_scaled)\n#         # show title\n#         pyplot.title(titles[i])\n    \n#     pyplot.tight_layout()\n#     pyplot.show()\n\n# [X1, X2] = datasetv2\n# src, tar = X1, X2\n\n# # === PHẦN SỬA LỖI: Thêm batch dimension ===\n# # Chuyển từ shape (256, 256, 3) thành (1, 256, 256, 3)\n# src_batch = np.expand_dims(src, axis=0)\n\n# # generate image from source\n# gen_batch = model.predict(src_batch)\n\n# # Loại bỏ batch dimension để về lại shape (256, 256, 3)\n# gen = np.squeeze(gen_batch, axis=0)\n\n# # plot all three images\n# plot_images(src, gen, tar)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# # === Load và xử lý ảnh source ===\n# img = load_img('/kaggle/input/aaaaasde/test2.png', target_size=(256, 256))\n# img_array = img_to_array(img)\n\n# print(f\"Original image range: [{img_array.min():.2f}, {img_array.max():.2f}]\")\n# print(f\"Original image shape: {img_array.shape}\")\n\n# # Scale từ [0,255] về [-1,1] giống lúc train\n# img_array = (img_array - 127.5) / 127.5\n# print(f\"Normalized image range: [{img_array.min():.2f}, {img_array.max():.2f}]\")\n\n# # Thêm batch dimension\n# src_image = np.expand_dims(img_array, axis=0)  # (1, 256, 256, 3)\n\n# # === Dự đoán ===\n# gen_image = model.predict(src_image, verbose=0)\n# print(f\"Generated image range: [{gen_image.min():.2f}, {gen_image.max():.2f}]\")\n\n# # === Vẽ ảnh Source và Generated ===\n# def plot_images_debug(src_img, gen_img):\n#     # scale từ [-1,1] về [0,1] để hiển thị\n#     src_display = (src_img + 1) / 2.0\n#     gen_display = (gen_img + 1) / 2.0\n    \n#     # Clip để đảm bảo trong khoảng [0,1]\n#     src_display = np.clip(src_display, 0, 1)\n#     gen_display = np.clip(gen_display, 0, 1)\n    \n#     images = [src_display[0], gen_display[0]]\n#     titles = ['Source', 'Generated']\n    \n#     plt.figure(figsize=(12, 6))\n#     for i in range(2):\n#         plt.subplot(1, 2, i + 1)\n#         plt.axis('off')\n#         plt.title(titles[i])\n#         plt.imshow(images[i])\n        \n#         # Thêm thông tin về range\n#         img_min, img_max = images[i].min(), images[i].max()\n#         plt.xlabel(f'Range: [{img_min:.3f}, {img_max:.3f}]')\n    \n#     plt.tight_layout()\n#     plt.show()\n\n# plot_images_debug(src_image, gen_image)\n\n# # === Thêm histogram để so sánh phân phối ===\n# def plot_histograms(src_img, gen_img):\n#     plt.figure(figsize=(12, 4))\n    \n#     # Histogram của source image\n#     plt.subplot(1, 2, 1)\n#     plt.hist(src_img.flatten(), bins=50, alpha=0.7, color='blue')\n#     plt.title('Source Image Histogram')\n#     plt.xlabel('Pixel Value')\n#     plt.ylabel('Frequency')\n    \n#     # Histogram của generated image\n#     plt.subplot(1, 2, 2)\n#     plt.hist(gen_img.flatten(), bins=50, alpha=0.7, color='red')\n#     plt.title('Generated Image Histogram')\n#     plt.xlabel('Pixel Value')\n#     plt.ylabel('Frequency')\n    \n#     plt.tight_layout()\n#     plt.show()\n\n# plot_histograms(src_image, gen_image)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/checkpoints.zip /kaggle/working/checkpoints\n!zip -r /kaggle/working/logs.zip /kaggle/working/logs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shutil\n\n# # Copy file checkpoint\n# shutil.copy('/kaggle/working/checkpoints/d_model.weights.h5', '/kaggle/working/d_model.weights.h5')\n# shutil.copy('/kaggle/working/checkpoints/g_model.weights.h5', '/kaggle/working/g_model.weights.h5')\n# shutil.copy('/kaggle/working/checkpoints/gan_model.weights.h5', '/kaggle/working/gan_model.weights.h5')\n# shutil.copy('/kaggle/working/checkpoints/checkpoint.json', '/kaggle/working/checkpoint.json')\n\n# # Copy file logs\n# shutil.copytree('/kaggle/working/logs/20250521-114829', '/kaggle/working/logs_copy')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tensorboard --logdir=\"D:\\AI\\kaggle\\working\\logs\\20250521-114829\"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}